{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "cudnn.benchmark = True\n",
    "import sklearn.metrics as metrics\n",
    "from PIL import Image\n",
    "from prettytable import PrettyTable\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"Z://RR/Final/report_work/results/Trained_on_FairFace_Testing/FairFace_tests\"\n",
    "\n",
    "model_name = 'ResNet34_v21_5'\n",
    "model_path = F\"Z://RR/Final/report_work/saved_models/FairFace_All_Races_Testing/{model_name}.pt\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_path = 'Z://RR/Final/Datasets/FairFace_All_Races_Testing/test'\n",
    "\n",
    "\n",
    "def show_image(file_path):\n",
    "\t# full_path = file_prefix + '/'+file_path\n",
    "\timg = cv2.imread(file_path)[:,:,::-1]\n",
    "\tplt.imshow(img)\n",
    "\tplt.show()\n",
    " \n",
    "df_path ='Z://RR/FairFace/labels/fairface_label_full_allocated.csv'\n",
    "FairFace_df = pd.read_csv(df_path)\n",
    "# FairFace_df = FairFace_df[FairFace_df['Split'] == 'Test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14655"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = FairFace_df[FairFace_df['Split'] == 'Train']\n",
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97698, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FairFace_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "\t'test': transforms.Compose([ #compose several transforms together\n",
    "\t\ttransforms.Resize(224),\n",
    "\t\ttransforms.RandomHorizontalFlip(),\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t\t# transforms.Normalize(mean, std)\n",
    "\t]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, load_path):\n",
    "\tif torch.cuda.is_available():\n",
    "\t\t\n",
    "\t\tcheckpoint = torch.load(load_path)\n",
    "\telse:\n",
    "\t\tcheckpoint = torch.load(load_path,map_location=torch.device('cpu'))\n",
    "\t\t\n",
    "\tmodel.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def get_model_data(class_names):\n",
    "\tweights = models.ResNet34_Weights.DEFAULT\n",
    "\tmodel_ft = models.resnet34(weights = weights)\n",
    "\tnum_ftrs = model_ft.fc.in_features\n",
    " \n",
    "\tmodel_ft.fc = nn.Linear(num_ftrs,len(class_names))\n",
    " \n",
    "\tmodel_ft= load_checkpoint(model_ft, model_path)\n",
    " \n",
    "\tmodel_ft = model_ft.to(device)\n",
    "\tmodel_ft.eval()\n",
    " \n",
    "\treturn model_ft\n",
    "\n",
    "def get_pred(model,file):\n",
    "\timg = Image.open(file)\n",
    "\tinput = data_transforms['test'](img)\n",
    "\tinput = input.unsqueeze(0)\n",
    "\tinput = input.to(device)\n",
    "\twith torch.set_grad_enabled(False):\n",
    "\t\toutput = model(input)\n",
    "\t\t_, preds = torch.max(output, 1)\n",
    "\t\n",
    "\treturn preds[0].item() \n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = FairFace_df.age.value_counts().reset_index(name = \"count\").rename(columns={\"index\":\"age\"})['age']\n",
    "model = get_model_data(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prefix = 'Z://RR/FairFace/images/archive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14655/14655 [31:18<00:00,  7.80it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index in tqdm(FairFace_df.index):\n",
    "# for index in FairFace_df.index[:5]:\n",
    "\t\n",
    "    \n",
    "\tpath = os.path.join(image_prefix,FairFace_df.at[index,'file'])\n",
    "\tif os.path.isfile(path):\n",
    "\t\tclass_pred = get_pred(model,path)\n",
    "\t\n",
    "\t\tFairFace_df.at[index,'prediction'] = class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FairFace_df = FairFace_df[FairFace_df['prediction'].notna()]\n",
    "# FairFace_df = FairFace_df[FairFace_df.prediction.map(type)==np.float64]\n",
    "\n",
    "age_dist = FairFace_df.age.value_counts().reset_index(name = \"count\").rename(columns={\"index\":\"age\"})\n",
    "age_dist.sort_values(by = ['age'],inplace=True)\n",
    "age_dist = age_dist.reset_index(drop=True)\n",
    "age_groups = age_dist['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(pred):\n",
    "    for i,group in enumerate(age_groups):\n",
    "        if group == pred:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FairFace_df['pred_age_group'] = FairFace_df['prediction'].apply(lambda x: age_groups[x])\n",
    "FairFace_df['true'] = FairFace_df['age'].apply(lambda x: convert(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FairFace_df.to_csv(output_path+'/FairFace_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01b0da322a7df2b881bf69dce4c75684d5ac75b853286a49a713693279c2c23c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
